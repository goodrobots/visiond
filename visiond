#!/srv/maverick/software/python/bin/python3

# (c) 2016-2017 Fnoop
# http://github.com/goodrobots/maverick
# This is an experimental daemon that controls a video source, transmutes formats and transmits it over wireless

import io
import os
import sys
import signal
import time
import logging
import errno
import re
import configparser as ConfigParser
import traceback
import subprocess
import glob
import v4l2
from fcntl import ioctl
import gi
from importlib import import_module
import lockfile, signal, grp
from daemon import runner

gi.require_version('Gst', '1.0')
gi.require_version('GstRtspServer', '1.0')
from gi.repository import GObject,GLib,Gst,GstRtspServer
GObject.threads_init()
Gst.init(None)

### Streamer Class to build up Gstreamer pipeline from in to out
class Streamer(object):
    def __init__(self,width,height,framerate,format,pixelformat,encoder,input,source,brightness,output,dest,port):
        self.size = 0
        self.playing = False
        self.paused = False
        self.format = format
        self.encoder = encoder
        self.payload = None # This is worked out later based on encoding and output type
        self.width = width
        self.height = height
        self.framerate = framerate
        self.output = output

        # Start with creating a pipeline from source element
        if input == "appsrc":
            self.input_appsrc()
        elif input == "v4l2":
            self.input_v4l2(source, brightness)
        
        # Next deal with each input format separately and interpret the stream and encoding method to the pipeline
        if format == "h264":
            self.capstring = 'video/x-h264,width='+str(width)+',height='+str(height)+',framerate='+str(framerate)+'/1'
            self.stream_h264()
        elif format == "mjpeg":
            self.capstring = 'image/jpeg,width='+str(width)+',height='+str(height)+',framerate='+str(framerate)+'/1'
            self.stream_mjpeg()
        elif format == "yuv":
            if pixelformat:
                self.capstring = 'video/x-raw,format='+pixelformat+',width='+str(width)+',height='+str(height)+',framerate='+str(framerate)+'/1'
            else:
                self.capstring = None
            self.stream_yuv()
        else:
            logger.critical("Stream starting with unrecognised video format: " + str(format))
            return
        
        # Next choose the encoder
        if encoder == format:
            self.encode_attach = self.source_attach
            pass
        elif encoder == "h264":
            self.encode_h264()
        elif encoder == "mjpeg":
            self.encode_mjpeg()
        elif encoder == "yuv":
            self.encode_yuv()
        else:
            logger.critical("Stream starting with unrecognised encoder: " + str(encoder))
            return
        
        # Then work out which payload we want.  We only want a payload for unicast udp
        if output == "udp" or output == "rtsp":
            if encoder == "h264":
                self.payload = "rtp264pay"
                self.payload_h264()
            elif encoder == "mjpeg":
                self.payload = "rtpjpegpay"
                self.payload_mjpeg()
        else:
            self.payload_attach = self.encode_attach

        # Finally connect the requested output to the end of the pipeline
        if output == "file":
            self.output_file(dest)
        elif output == "udp":
            self.output_udp(dest, port)
        elif output == "dynudp":
            self.output_dynudp()
        elif output == "rtsp":
            self.output_rtsp(dest, port)
        elif output == "wcast":
            self.output_wcast(dest, port)

        # Start the pipeline
        self.show_pipeline()
        self.bus()
        self.start()


    def show_pipeline(self):        
        # Output the resulting pipeline construction to log
        pipeline_iterator = Gst.Bin.iterate_elements(self.pipeline)
        pipe_elements = []
        while True:
            res = Gst.Iterator.next(pipeline_iterator)
            if res[1]:
                elemstr = res[1].name
                # Extract caps if capsfilter element
                if res[1].name == "capsfilter":
                    elemstr += " '" + Gst.Caps.to_string(res[1].get_property('caps')) + "'"
                # Extract device if v4l2src element
                if res[1].name == "v4l2-source":
                    elemstr += " " + res[1].get_property('device')
                # Add element to pipeline output
                pipe_elements.append(elemstr)
                # logger.debug("Element: "+str(res[1]))
            if res[0] == Gst.IteratorResult.DONE:
                break
        logger.info("Pipeline: \"" + " ! ".join(list(reversed(pipe_elements))) +"\"")
        
    ### Input methods
    def input_appsrc(self):
        logger.info("Attaching input 'appsrc'")
        self.pipeline = Gst.Pipeline.new()
        self.source = Gst.ElementFactory.make("appsrc", "source")
        self.pipeline.add(self.source)
        # Set appsrc stream to live
        self.source.set_property("is-live",True)
        # Let appsrc set the timestamp so we don't have to do it
        self.source.set_property("do-timestamp",True)
        self.source.set_property("min-latency",0)
    
    def input_v4l2(self, source, brightness):
        if not source:
            source = "/dev/video0"
        logger.info("Attaching input 'v4l2': "+str(source))
        self.pipeline = Gst.Pipeline.new()
        self.source = Gst.ElementFactory.make("v4l2src", "v4l2-source")
        self.source.set_property("device", source)
        self.source.set_property("brightness", brightness)
        self.pipeline.add(self.source)

    ### Stream methods
    def stream_h264(self):
        logger.info("Attaching stream 'h264'")
        capsfilter = Gst.ElementFactory.make("capsfilter", "capsfilter")
        capsfilter.set_property('caps', Gst.Caps.from_string(self.capstring))
        self.pipeline.add(capsfilter)
        self.source.link(capsfilter)
        """
        # Try and construct a parse element.
        parse = Gst.ElementFactory.make("h264parse", "h264parse")
        if parse:
            logger.debug('h264parse element created')
            self.pipeline.add(parse)
            capsfilter.link(parse)
        h264pay = Gst.ElementFactory.make("rtph264pay", "h264-payload")
        h264pay.set_property("config-interval", 1)
        h264pay.set_property("pt", 96)
        h264pay.set_property("name", "pay0") # Set pay%d for rtsp stream pickup
        self.pipeline.add(h264pay)
        if parse:
            logger.debug('Attaching h264pay to h264parse')
            parse.link(h264pay)
        else:
            logger.debug('Attaching h264pay direct to capsfilter')
            capsfilter.link(h264pay)
        self.source_attach = h264pay
        """
        self.source_attach = capsfilter

    def stream_mjpeg(self):
        logger.info("Attaching stream 'mjpeg'")
        capsfilter = Gst.ElementFactory.make("capsfilter", "capsfilter")
        capsfilter.set_property('caps', Gst.Caps.from_string(self.capstring))
        self.pipeline.add(capsfilter)
        self.source.link(capsfilter)
        # Try and construct a parse element.
        parse = Gst.ElementFactory.make("jpegparse", "jpegparse")
        if parse:
            self.pipeline.add(parse)
            capsfilter.link(parse)
        queue = Gst.ElementFactory.make("queue", "queue")
        if self.format != self.encoder:
            dec = None
            # if Gst.ElementFactory.find("omxmjpegdec"):
            if Gst.ElementFactory.find("omxmjpegdecDISABLED"):
                logger.info("Raspberry hardware decoder detected, using omxmjpegdec as mjpeg decoder")
                dec = Gst.ElementFactory.make("omxmjpegdec", "omxmjpegdec")
            elif Gst.ElementFactory.find("jpegdec"):
                dec = Gst.ElementFactory.make("jpegdec", "jpegdec")
            if not dec:
                logger.critical("Error: No jpeg decoder found for mjpeg stream, exiting")
                sys.exit(1)
            self.pipeline.add(dec)
            if parse:
                parse.link(dec)
            else:
                capsfilter.link(dec)
            self.pipeline.add(queue)
            dec.link(queue)
        else:
            self.pipeline.add(queue)
            if parse:
                parse.link(queue)
            else:
                capsfilter.link(queue)
        vconvert = Gst.ElementFactory.make("videoconvert", "videoconvert")
        self.pipeline.add(vconvert)
        queue.link(vconvert)
        self.source_attach = vconvert
        
    def stream_yuv(self):
        logger.info("Attaching stream 'yuv'")
        if self.capstring:
            capsfilter = Gst.ElementFactory.make("capsfilter", "capsfilter")
            capsfilter.set_property('caps', Gst.Caps.from_string(self.capstring))
            self.pipeline.add(capsfilter)
            self.source.link(capsfilter)
        queue = Gst.ElementFactory.make("queue", "queue")
        self.pipeline.add(queue)
        if self.capstring:
            capsfilter.link(queue)
        else:
            self.source.link(queue)
        vconvert = Gst.ElementFactory.make("autovideoconvert", "autovideoconvert")
        if not vconvert:
            vconvert = Gst.ElementFactory.make("videoconvert", "videoconvert")
        self.pipeline.add(vconvert)
        queue.link(vconvert)
        self.source_attach = vconvert

    ### Encoding methods
    def encode_h264(self):
        logger.info("Attaching encoding 'h264'")
        # Try and detect encoder
        self.h264enc = None
        # Detect Raspberry/OMX
        if Gst.ElementFactory.find("omxh264enc"):
            logger.info("Raspberry hardware encoder detected, using omxh264enc as h264 encoder")
            self.h264enc = Gst.ElementFactory.make("omxh264enc", "raspberry-h264-encode")
            self.h264enc.set_property('control-rate', 'variable')
            self.h264enc.set_property('target-bitrate', 2000000)
        """
        # Detect Odroid/MFC
        # Note this is disabled as it is now triggered on Raspberry and possibly other platforms, with latest gstreamer
        try:
            odroid264encoder = subprocess.check_output("gst-inspect-1.0 video4linux2 | grep 'H.264 Encoder' |awk -F: {'print $1'} |sed 's/\s//g' |tr -d '\n'", shell=True)
            if odroid264encoder:
                logger.info("Odroid MFC hardware encoder detected, attempting to use "+odroid264encoder+" as h264 encoder")
                self.h264enc = Gst.ElementFactory.make(odroid264encoder, "odroid-h264-encode")
                h264struct = Gst.Structure.new_empty("v4lencoder-extracontrols")
                h264struct.encode = True
                h264struct.h264_level = 10
                h264struct.h264_profile = 4
                h264struct.frame_level_rate_control_enable = 1
                h264struct.frame_skip_enable = 1
                h264struct.video_bitrate = 2000000
                self.h264enc.set_property('extra-controls', h264struct)
        except subprocess.CalledProcessError as e:
            pass
        """
        # Detect Intel/VAAPI
        try:
            # Determine vaapi encoder exists, but suppress output
            with open(os.devnull, "w") as devnull:
                vaapi264encoder = subprocess.call(["gst-inspect-1.0", "vaapih264enc"], stdout=devnull, stderr=devnull)
            if not vaapi264encoder:
                logger.info("VAAPI hardware encoder detected, attempting to use vaapi as h264 encoder")
                self.h264enc = Gst.ElementFactory.make("vaapih264enc", "vaapih264enc")
        except subprocess.CalledProcessError as e:
            pass
        # Otherwise use software encoder
        if not self.h264enc:
            logger.info("No hardware encoder detected, using software x264 encoder")
            self.h264enc = Gst.ElementFactory.make("x264enc", "x264-encode")
            self.h264enc.set_property('speed-preset', 1)
            self.h264enc.set_property('tune', 0x00000004)
        self.pipeline.add(self.h264enc)
        self.source_attach.link(self.h264enc)
        # If using raspberry hardware encoder, specify caps explicitly otherwise it can get upset when using rtspserver
        if Gst.ElementFactory.find("omxh264enc"):
            x264capsfilter = Gst.ElementFactory.make("capsfilter", "x264capsfilter")
            x264capsfilter.set_property('caps', Gst.Caps.from_string("video/x-h264,profile=high,width={},height={},framerate={}/1".format(self.width,self.height,self.framerate)))
            self.pipeline.add(x264capsfilter)
            self.h264enc.link(x264capsfilter)
            self.encode_attach = x264capsfilter
        else:
            self.encode_attach = self.h264enc
        
    def encode_mjpeg(self):
        # TODO: Add actual mjpeg encoding, currently we just pass through the source to the encoder attach points
        if self.format == self.encoder:
            self.encode_attach = self.source_attach
        else:
            self.encode_attach = self.source_attach
        
    def encode_yuv(self):
        # Nothing todo, just hang the source onto the encoder attach point
        self.encode_attach = self.source_attach

    ### Payload methods
    def payload_h264(self):
        logger.info("Attaching payload 'h264'")
        # Try and construct a parse element.  This will fail on later (1.9+) gstreamer versions, so the subsequent (if parse) code bypasses if not present
        parse = Gst.ElementFactory.make("h264parse", "h264parse")
        if parse:
            logger.debug('h264parse element created')
            self.pipeline.add(parse)
            self.encode_attach.link(parse)
        h264pay = Gst.ElementFactory.make("rtph264pay", "h264-payload")
        h264pay.set_property("config-interval", 1)
        h264pay.set_property("pt", 96)
        h264pay.set_property("name", "pay0") # Set pay%d for rtsp stream pickup
        self.pipeline.add(h264pay)
        if parse:
            logger.debug('Attaching h264pay to h264parse')               
            parse.link(h264pay)
        else:
            logger.debug('Attaching h264pay direct to h264 encoder')
            self.encode_attach.link(h264pay)
        self.payload_attach = h264pay
            
    def payload_mjpeg(self):
        logger.info("Attaching payload 'mjpeg'")
        mjpegpay = Gst.ElementFactory.make("rtpjpegpay", "mjpeg-payload")
        mjpegpay.set_property("pt", 26)
        self.pipeline.add(mjpegpay)
        self.encode_attach.link(mjpegpay)
        self.payload_attach = mjpegpay

    ### Output methods
    def output_file(self, dest):
        logger.info("Attaching output 'file'")
        mux = Gst.ElementFactory.make("mpegtsmux", "mux")
        self.pipeline.add(mux)
        self.payload_attach.link(mux)
        
        sink = Gst.ElementFactory.make("filesink", "sink")
        sink.set_property("location", dest)
        self.pipeline.add(sink)
        mux.link(sink)
    
    def output_udp(self, dest, port):
        if not dest:
            logger.warn("UDP destination must be set")
            return
        logger.info("Attaching output 'udp', sending to "+str(dest)+":"+str(port))
        sink = Gst.ElementFactory.make("udpsink", "udpsink")
        sink.set_property("host", dest)
        sink.set_property("port", port)
        sink.set_property("sync", False)
        self.pipeline.add(sink)
        self.payload_attach.link(sink)
    
    def output_wcast(self, dest, port):
        logger.info("Attaching output 'wcast'")
        # Create an OS pipe so we can attach the gstream pipeline to one end, and wifibroadcast tx to the other end
        read, write = os.pipe()
        # Create an fdsink to dump the pipeline out of
        sink = Gst.ElementFactory.make("fdsink", "fdsink")
        # Attach the sink to one end of the os pipe
        sink.set_property("fd", write)
        sink.set_property("sync", False)
        self.pipeline.add(sink)
        self.payload_attach.link(sink)
        # Spawn wifibroadcast tx
        self.wcast_tx = subprocess.Popen(['/srv/maverick/software/wifibroadcast/tx','-b 8', '-r 4', '-f 1024', dest], stdin=read)
        logger.info("wcast tx pid:" + str(self.wcast_tx.pid))
        signal.signal(signal.SIGTERM, self.shutdown_tx)

    def output_dynudp(self):
        logger.info("Attaching output 'dynudp'")
        sink = Gst.ElementFactory.make("dynudpsink", "dynudpsink")
        sink.set_property("sync", False)
        sink.set_property("bind-address", "0.0.0.0")
        sink.set_property("bind-port", 5554)
        self.pipeline.add(sink)
        self.encode_attach.link(sink)

    def output_rtsp(self, dest, port):
        logger.info("Attaching output 'rtsp'")
        self.rtspserver = GstRtspServer.RTSPServer()
        self.rtspserver.set_address(dest)
        self.rtspserver.set_service(str(port))

        try:
            # Here we override RTSPMediaFactory to use the constructed object pipeline rather than the usual
            #  set_launch which parses a pipeline string.
            self.rtspfactory = MavRTSPMediaFactory(self.pipeline)
        except Exception as e:
            logger.critical("Error creating rstpfactory: "+repr(e))
        
        # Add the /video endpoint.  More/dynamic endpoints will be added in the future
        self.rtspmounts = self.rtspserver.get_mount_points()
        self.rtspmounts.add_factory('/video', self.rtspfactory)
        self.rtspserver.attach(None)

        logger.info("RTSP stream running at rtsp://"+str(dest)+":"+str(port)+"/video")

    ### Misc methods (glib introspection)
    def on_message(self, bus, message):
        t = message.type
        if t == Gst.MessageType.EOS:
            self.pipeline.set_state(Gst.State.NULL)
            self.playing = False
        elif t == Gst.MessageType.ERROR:
            self.pipeline.set_state(Gst.State.NULL)
            err, debug = message.parse_error()
            print("Error: %s" % err, debug)
            self.playing = False

    def bus(self):
        bus = self.pipeline.get_bus()
        bus.add_signal_watch()
        bus.connect("message", self.on_message)

    ### Action methods
    def start(self):
        if self.output != "rtsp":
            self.pipeline.set_state(Gst.State.PLAYING)
            self.playing = True
        logger.info('Starting camera stream')
        GObject.MainLoop().run()

    def write(self,s):
        gstbuff = Gst.Buffer.new_wrapped(s)
        self.source.emit("push-buffer",gstbuff)

    def stop(self):
        self.pipeline.set_state(Gst.State.READY)
        self.playing = False
        logger.info('Stopping camera stream')

    def flush(self):
        self.stop()
        
    def shutdown_tx(self, signum, frame):
        os.kill(self.wcast_tx.pid, signal.SIGTERM)
        sys.exit()


### Create an RTSP Media Factory from an existing pipeline
class MavRTSPMediaFactory(GstRtspServer.RTSPMediaFactory):
    def __init__(self, pipeline):
        GstRtspServer.RTSPMediaFactory.__init__(self)
        self.set_shared(True)
        #self.set_reusable(True)
        self.set_eos_shutdown(False)
        self.set_buffer_size(0)
        #self.set_suspend_mode(GstRtspServer.RTSPMedia.GST_RTSP_SUSPEND_MODE_NONE)
        self.set_property('latency', 0)
        self.set_transport_mode(GstRtspServer.RTSPTransportMode.PLAY)
        self.pipeline = pipeline

    def do_create_element(self, url):
        logger.info("Creating RTSP factory element: {}".format(url))
        return self.pipeline


### Main App Class (initial concept)
class App():
    def __init__(self):
        self.stdin_path = '/dev/null'
        self.stdout_path = '/srv/maverick/var/log/vision/maverick-visiond.daemon.log'
        self.stderr_path = '/srv/maverick/var/log/vision/maverick-visiond.daemon.log'
        self.pidfile_path = '/srv/maverick/var/run/maverick-visiond.pid'
        self.pidfile_timeout = 5

    def run(self):
        logger.info("Starting maverick-visiond")

        # Get config
        self.config = self.config_parse("/srv/maverick/config/vision/maverick-visiond.conf")

        # If on/off switch is off, exit
        if self.config['enable'].lower() == 'false':
            logger.critical('Off switch is activated, exiting')
            sys.exit(0)

        if 'debug' in self.config and self.config['debug']:
            Gst.debug_set_active(True)
            Gst.debug_set_default_threshold(self.config['debug'])
        
        if 'retry' not in self.config or not self.config['retry']:
            self.retry = 30
        else:
            self.retry = self.config['retry']

        # Start the pipeline.  Trap any errors and wait for 30sec before trying again.
        while True:
            try:
                if 'pipeline_override' in self.config:
                    self.manualconstruct()
                else:
                    self.autoconstruct()
            except ValueError as e:
                logger.critical("Error constructing pipeline: {}, retrying in {} sec".format(repr(e), self.retry))
                time.sleep(float(self.retry))

    def manualconstruct(self):
        logger.info("Manual Pipeline Construction")
        logger.info("Creating pipeline from config: " + self.config['pipeline_override'])
        try:
            # Create the pipeline from config override
            self.pipeline = Gst.parse_launch(self.config['pipeline_override'])
            # Set pipeline to playing
            self.pipeline.set_state(Gst.State.PLAYING)
        except Exception as e:
            raise ValueError('Error constructing manual pipeline specified: {}'.format(repr(e)))
        while True:
            time.sleep(5)

    def autoconstruct(self):
        # If camera device set in config use it, otherwise autodetect
        cameradev = None
        devicepaths = glob.glob("/dev/video*")
        try:
            if self.config['camera_device']:
                cameradev = self.config['camera_device']
        except:
            # device not set, carry on and try to autodetect
            for devicepath in devicepaths:
                if self.check_input(devicepath):
                    cameradev = devicepath
                    logger.info('v4l2 device '+devicepath+' is a camera, autoselecting')
                else:
                    logger.debug('v4l2 device '+devicepath+' is not a camera, ignoring')
        if not cameradev:
            raise ValueError('Error detecting camera video device')

        # Check the camera has a valid input
        try:
            #self.vd = open(cameradev, 'r+')
            self.vd = io.TextIOWrapper(open(cameradev, "r+b", buffering=0))
            cp = v4l2.v4l2_capability()
        except Exception as e:
            raise ValueError("Camera not specified in config, or camera not valid: {}".format(repr(e)))
        if not self.check_input():
            raise ValueError('Specified camera not valid')

        # Log info
        self.camera_info()
        
        # Try and autodetect MFC device
        self.mfcdev = None
        for devicepath in devicepaths:
            dp = io.TextIOWrapper(open(devicepath, "r+b", buffering=0))
            ioctl(dp, v4l2.VIDIOC_QUERYCAP, cp)
            if cp.card == "s5p-mfc-enc":
                self.mfcdev = dp
                logger.info('MFC Hardware encoder detected, autoselecting '+devicepath)

        # If format set in config use it, otherwise autodetect
        streamtype = None
        try:
            if self.config['format']:
                streamtype = self.config['format']
        except:
            if re.search("C920", self.card.decode()):
                logger.info("Logitech C920 detected, forcing H264 passthrough")
                streamtype = 'h264'                                                                     
            # format not set, carry on and try to autodetect
            elif self.check_format('yuv'):
                logger.info('Camera YUV stream available, using yuv stream')
                streamtype = 'yuv'
            # Otherwise, check for an mjpeg->h264 encoder pipeline.
            elif self.check_format('mjpeg'):
                logger.info('Camera MJPEG stream available, using mjpeg stream')
                streamtype = 'mjpeg'
            # Lastly look for a h264 stream
            elif self.check_format('h264'):
                logger.info('Camera H264 stream available, using H264 stream')
                streamtype = 'h264'
        if not streamtype:
            raise ValueError('Error detecting camera video format')

        # If encoder set in config use it, otherwise set to h264
        encoder = None
        try:
            if self.config['encoder']:
                encoder = self.config['encoder']
        except:
            pass
        if not encoder:
            encoder = "h264"
        
        # If raspberry camera detected set pixelformat to I420, otherwise set to YUY2 by default
        pixelformat = "YUY2"
        ioctl(self.vd, v4l2.VIDIOC_QUERYCAP, cp) 
        if cp.driver == "bm2835 mmal":
            logger.info("Raspberry Pi Camera detected, setting pixel format to I420")
            pixelformat = "I420"
            
        # If raw pixelformat set in config override the defaults
        if 'pixelformat' in self.config:
                pixelformat = self.config['pixelformat']

        # Create the stream
        try:
            logger.info("Creating stream object - camera:"+cameradev+", stream:"+streamtype+", pixelformat:"+pixelformat+", encoder:"+encoder+", size:("+str(self.config['width'])+" x "+str(self.config['height'])+" / "+str(self.config['framerate'])+"), output:"+self.config['output']+", brightness:"+self.config['brightness'])
            Streamer(self.config['width'], self.config['height'], self.config['framerate'], streamtype, pixelformat, encoder, self.config['input'], cameradev, int(self.config['brightness']), self.config['output'], self.config['output_dest'], int(self.config['output_port']))
        except Exception as e:
            #logger.critical('Error creating '+streamtype+' stream:', traceback.print_exc())
            raise ValueError('Error creating '+streamtype+' stream: ' + str(repr(e)))

        while True:
            time.sleep(5)

    def config_parse(self, path):
        Config = ConfigParser.SafeConfigParser()
        options = {}
        try:
            Config.read(path)
            for item in Config.options("visiond"):
                options[item] = Config.get("visiond", item)
            logger.info("Config read from " + str(path))
        except:
            logger.critical("Error reading config file: " + str(path))
            sys.exit(1)
        return options
        
    def camera_info(self):
        # Log capability info
        cp = v4l2.v4l2_capability() 
        ioctl(self.vd, v4l2.VIDIOC_QUERYCAP, cp) 
        logger.debug("driver: " + cp.driver.decode())
        logger.debug("card: " + cp.card.decode())
        self.driver = cp.driver
        self.card = cp.card
        
        # Log controls available
        queryctrl = v4l2.v4l2_queryctrl(v4l2.V4L2_CID_BASE)
        while queryctrl.id < v4l2.V4L2_CID_LASTP1:
            try:
                ioctl(self.vd, v4l2.VIDIOC_QUERYCTRL, queryctrl)
            except IOError as e:
                # this predefined control is not supported by this device
                assert e.errno == errno.EINVAL
                queryctrl.id += 1
                continue
            logger.debug("Camera control: " + queryctrl.name.decode())
            queryctrl = v4l2.v4l2_queryctrl(queryctrl.id + 1)
        queryctrl.id = v4l2.V4L2_CID_PRIVATE_BASE
        while True:
            try:
                ioctl(self.vd, v4l2.VIDIOC_QUERYCTRL, queryctrl)
            except IOError as e:
                # no more custom controls available on this device
                assert e.errno == errno.EINVAL
                break
            logger.debug("Camera control: " + queryctrl.name.decode())
            queryctrl = v4l2.v4l2_queryctrl(queryctrl.id + 1)
        
        # Log formats available
        capture = v4l2.v4l2_fmtdesc()
        capture.index = 0
        capture.type = v4l2.V4L2_BUF_TYPE_VIDEO_CAPTURE
        try:
            while (ioctl(self.vd, v4l2.VIDIOC_ENUM_FMT, capture) >= 0):
                    logger.debug("Camera format: " + capture.description.decode())
                    capture.index += 1
        except:
            pass
        
    def check_input(self, vd=None, index=0):
        if vd == None:
            vd = self.vd
        else:
            vd = io.TextIOWrapper(open(vd, "r+b", buffering=0))
        input = v4l2.v4l2_input(index)
        try:
            ioctl(vd, v4l2.VIDIOC_ENUMINPUT, input)
            logger.debug('V4l2 device input: ' + input.name.decode() + ':' + str(input.type))
            if input.type != 2:
                return False # If input type is not camera (2) then return false
            return True
        except Exception as e:
            logger.debug("Error checking input: {}".format(repr(e)))
            return False

    def check_format(self, format):
        capture = v4l2.v4l2_fmtdesc()
        capture.index = 0
        capture.type = v4l2.V4L2_BUF_TYPE_VIDEO_CAPTURE
        available = False
        try:
            while (ioctl(self.vd, v4l2.VIDIOC_ENUM_FMT, capture) >= 0):
                logger.debug("Format: {} : {}".format(format, capture.description.decode()))
                if format.lower() == "h264":
                    if re.search('H264', capture.description.decode().lower()) or re.search('H.264', capture.description.decode().lower()):
                        available = True
                elif format.lower() == "mjpeg":
                    if re.search('jpeg', capture.description.decode().lower()):
                        available = True
                elif format.lower() == "yuv" or format.lower() == "raw":
                    if re.search('^yu', capture.description.decode().lower()):
                        available = True
                else:
                    if re.search(format.lower(), capture.description.decode().lower()):
                        available = True
                capture.index += 1
        except:
            pass
        return available

 
if __name__ == "__main__":
    print("Starting maverick-visiond")

    # Setup logging
    logger = logging.getLogger("DaemonLog")
    logger.setLevel(logging.DEBUG)
    formatter = logging.Formatter("%(asctime)s - %(levelname)s - %(message)s")
    handler = logging.FileHandler("/srv/maverick/var/log/vision/maverick-visiond.log")
    handler.setFormatter(formatter)
    logger.addHandler(handler)
    
    # Create app instance and daemonize
    app = App()
    app.run()
    """
    daemon_runner = runner.DaemonRunner(app)
    daemon_runner.daemon_context.files_preserve=[handler.stream]
    try:
        daemon_runner.do_action()
    except runner.DaemonRunnerStopFailureError as Error:
        print " - visiond not running, cannot stop"
        # If stop action, just ignore the error and exit
        if daemon_runner.action == "stop":
            sys.exit(0)
        elif daemon_runner.action == "restart":
            print " - starting visiond"
            daemon_runner.action = "start"
            daemon_runner.do_action()
    """            
    # logger.info("Stopping maverick-visiond")
    print("Stopped maverick-visiond daemon")
